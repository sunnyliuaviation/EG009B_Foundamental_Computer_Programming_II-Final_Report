{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f25f25dc",
   "metadata": {},
   "source": [
    "### 完整程式碼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e478a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, random, csv              # 匯入必要模組\n",
    "from bs4 import BeautifulSoup             # 匯入 HTML 解析工具\n",
    "\n",
    "def get_comic_info():\n",
    "    while True:  # while True 是為了「保證拿到一筆有效的漫畫資料」，不管遇到什麼失敗都會重試，直到成功為止。\n",
    "        n = random.randint(1, 3086)  # 隨機選一篇漫畫（1 <= n <= 3086）\n",
    "        url = f'https://xkcd.com/{n}/'  # 組成漫畫網址\n",
    "\n",
    "        r = requests.get(url)  # 發送 GET 請求\n",
    "\n",
    "        if r.status_code == 200:  # 檢查回應狀態碼是否為 200（代表請求成功）\n",
    "            # 請求成功，處理內容\n",
    "            soup = BeautifulSoup(r.text, 'html.parser')  # 解析 HTML\n",
    "            title = soup.find('div', id='ctitle')  # 找標題\n",
    "        else:\n",
    "            get_comic_info()  # 若請求不成功，則重新呼叫\n",
    "\n",
    "        if not title:  # 如果找不到標題，表示頁面異常\n",
    "            continue   # 跳過這次，重試\n",
    "\n",
    "        return {  # 成功擷取資料後，回傳字典格式\n",
    "            'Comic Number': n,              # 漫畫編號\n",
    "            'Title': title.text.strip(),    # 標題文字（去除多餘空白）\n",
    "            'Comic URL': url                # 網頁網址\n",
    "        }\n",
    "\n",
    "def save_to_csv(data, f='xkcd_comics.csv'):\n",
    "    # 將資料儲存到 CSV 檔案中（append，避免覆蓋原資料）\n",
    "    with open(f, \"a\", newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=data.keys())  # 建立 CSV 寫入並寫入，欄位為資料的 key\n",
    "        writer.writerow(data)  # 寫入一筆漫畫資料\n",
    "\n",
    "# 主程式執行流程\n",
    "comic = get_comic_info()  # 取得一筆隨機漫畫資訊\n",
    "save_to_csv(comic)        # 將該筆資料寫入 CSV 檔案"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd6184e",
   "metadata": {},
   "source": [
    "### 程式碼製作步驟  \n",
    "* 先把需要做到的事情分成幾個 pieces，最後再 combine。\n",
    "* 我們需要隨機產生數字、寫入 csv 檔案、爬蟲\n",
    "* 有學過的觀念先寫出來，爬蟲最後再參考網路資料撰寫\n",
    "* 思考需要什麼->回顧這學期內容->有哪些內容是我們在報告中需要用到的先整理出來->little piece of code->flow chart、logic->combine code->debug\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e736ce50",
   "metadata": {},
   "source": [
    "1. 我們需要用到的模組有(需要 import):  \n",
    "\n",
    "    | 需要的功能 | import |\n",
    "    | --------- | ------ |\n",
    "    | 隨機產生數字 | random |\n",
    "    | 匯入 csv | csv |\n",
    "    | 發送 HTTP 請求，抓取網頁資料 | reqests |\n",
    "    | 解析網頁 | BeautifulSoup |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deff0ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, random, csv              # 匯入必要模組\n",
    "from bs4 import BeautifulSoup             # 取得網頁時，得到的只是原始 HTML 文字。BeautifulSoup 可以看懂 HTML 結構，讓我們可以很容易地找到想要的部分。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca70408e",
   "metadata": {},
   "source": [
    "2. 定義一個函示可以隨機產生漫畫編號並產出網址  \n",
    "   * 定義 comic 為這個函示呼叫出的資訊\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c157274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comic_info():  \n",
    "        n = random.randint(1, 3086)  # 隨機選一篇漫畫（1 <= n <= 3086）\n",
    "        url = f'https://xkcd.com/{n}/'  # 組成漫畫網址，並定義為 url\n",
    "comic = get_comic_info() #呼叫 get_comic_info() 這個函式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ad69fd",
   "metadata": {},
   "source": [
    "3. 希望寫入在 csv 的資料有漫畫編號、標題文字、網頁網址  \n",
    "    * 這些資料要用字典儲存，有 key 與 value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44e4c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "return {  # 成功擷取資料後，回傳字典格式\n",
    "    'Comic Number': n,              # 漫畫編號\n",
    "    'Title': title.text.strip(),    # 標題文字（去除多餘空白）\n",
    "    'Comic URL': url                # 網頁網址\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3800f427",
   "metadata": {},
   "source": [
    "4. 定義一個函示可以將資料寫入 CSV 檔案\n",
    "   * 希望以字典的格式儲存，因此使用 csv.DictWriter\n",
    "   * 將步驟 2 的 comic 資訊寫入 csv   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f498dc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(data, f='xkcd_comics.csv'):\n",
    "    # 將資料儲存到 CSV 檔案中（append，避免覆蓋原資料）\n",
    "    with open(f, \"a\", newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=data.keys())  # 建立 CSV 並寫入，欄位為資料的 key\n",
    "        writer.writerow(data)  # 寫入一筆漫畫資料\n",
    "\n",
    "comic = get_comic_info()  # 取得一筆隨機漫畫資訊\n",
    "save_to_csv(comic)        # 將該筆資料寫入 CSV 檔案"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9dfe71",
   "metadata": {},
   "source": [
    "5. 爬蟲階段製作: 先對網頁發送請求，檢查是否有回應  \n",
    "    * 如果有回應，繼續執行\n",
    "    * 沒有回應，重新呼叫重新呼叫 get_comic_info() 函式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18ee974",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url)  # 發送 GET 請求\n",
    "if r.status_code == 200:  # 檢查回應狀態碼是否為 200（代表請求成功）\n",
    "else:\n",
    "    get_comic_info()  # 若請求不成功，則重新呼叫"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf545f88",
   "metadata": {},
   "source": [
    "6. 爬蟲階段製作: 放在步驟 5 的 if 條件式裡(如果 if 成立，則解析 HTML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fae59f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r.text, 'html.parser')  # 解析 HTML\n",
    "title = soup.find('div', id='ctitle')  # 找標題"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edd8367",
   "metadata": {},
   "source": [
    "7. 爬蟲階段製作: 確認步驟 6 是否找得到標題\n",
    "    * 找不到: 重試\n",
    "    * 找得到: 回傳步驟 3 的字典格式 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec3c3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not title:  # 如果找不到標題，表示頁面異常\n",
    "    continue   # 跳過這次，重試"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a059a6",
   "metadata": {},
   "source": [
    "8. 合併程式碼: 程式碼第 18 行報錯，需進行 debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f1ea68",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'continue' not properly in loop (1887940790.py, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[11], line 18\u001b[1;36m\u001b[0m\n\u001b[1;33m    continue   # 跳過這次，重試\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'continue' not properly in loop\n"
     ]
    }
   ],
   "source": [
    "import requests, random, csv              # 匯入必要模組\n",
    "from bs4 import BeautifulSoup             # 匯入 HTML 解析工具\n",
    "\n",
    "def get_comic_info():\n",
    "        n = random.randint(1, 3086)  # 隨機選一篇漫畫（1 <= n <= 3086）\n",
    "        url = f'https://xkcd.com/{n}/'  # 組成漫畫網址\n",
    "\n",
    "        r = requests.get(url)  # 發送 GET 請求\n",
    "\n",
    "        if r.status_code == 200:  # 檢查回應狀態碼是否為 200（代表請求成功）\n",
    "            # 請求成功，處理內容\n",
    "            soup = BeautifulSoup(r.text, 'html.parser')  # 解析 HTML\n",
    "            title = soup.find('div', id='ctitle')  # 找標題\n",
    "        else:\n",
    "            get_comic_info()  # 若請求不成功，則重新呼叫\n",
    "\n",
    "        if not title:  # 如果找不到標題，表示頁面異常\n",
    "            continue   # 跳過這次，重試\n",
    "\n",
    "        return {  # 成功擷取資料後，回傳字典格式\n",
    "            'Comic Number': n,              # 漫畫編號\n",
    "            'Title': title.text.strip(),    # 標題文字（去除多餘空白）\n",
    "            'Comic URL': url                # 網頁網址\n",
    "        }\n",
    "\n",
    "def save_to_csv(data, f='xkcd_comics.csv'):\n",
    "    # 將資料儲存到 CSV 檔案中（append，避免覆蓋原資料）\n",
    "    with open(f, \"a\", newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=data.keys())  # 建立 CSV 寫入並寫入，欄位為資料的 key\n",
    "        writer.writerow(data)  # 寫入一筆漫畫資料\n",
    "\n",
    "# 主程式執行流程\n",
    "comic = get_comic_info()  # 取得一筆隨機漫畫資訊\n",
    "save_to_csv(comic)        # 將該筆資料寫入 CSV 檔案"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f623aec",
   "metadata": {},
   "source": [
    "9. 完整程式碼: 經 google 後發現，continue 須放在迴圈裡，像是 while 或 for，因此選擇用 while True， 當條件成立時繼續往下執行。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d4aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, random, csv              # 匯入必要模組\n",
    "from bs4 import BeautifulSoup             # 匯入 HTML 解析工具\n",
    "\n",
    "def get_comic_info():\n",
    "    while True:  # while True 是為了「保證拿到一筆有效的漫畫資料」，不管遇到什麼失敗都會重試，直到成功為止。\n",
    "        n = random.randint(1, 3086)  # 隨機選一篇漫畫（1 <= n <= 3086）\n",
    "        url = f'https://xkcd.com/{n}/'  # 組成漫畫網址\n",
    "\n",
    "        r = requests.get(url)  # 發送 GET 請求\n",
    "\n",
    "        if r.status_code == 200:  # 檢查回應狀態碼是否為 200（代表請求成功）\n",
    "            # 請求成功，處理內容\n",
    "            soup = BeautifulSoup(r.text, 'html.parser')  # 解析 HTML\n",
    "            title = soup.find('div', id='ctitle')  # 找標題\n",
    "        else:\n",
    "            get_comic_info()  # 若請求不成功，則重新呼叫\n",
    "\n",
    "        if not title:  # 如果找不到標題，表示頁面異常\n",
    "            continue   # 跳過這次，重試\n",
    "\n",
    "        return {  # 成功擷取資料後，回傳字典格式\n",
    "            'Comic Number': n,              # 漫畫編號\n",
    "            'Title': title.text.strip(),    # 標題文字（去除多餘空白）\n",
    "            'Comic URL': url                # 網頁網址\n",
    "        }\n",
    "\n",
    "def save_to_csv(data, f='xkcd_comics.csv'):\n",
    "    # 將資料儲存到 CSV 檔案中（append，避免覆蓋原資料）\n",
    "    with open(f, \"a\", newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=data.keys())  # 建立 CSV 寫入並寫入，欄位為資料的 key\n",
    "        writer.writerow(data)  # 寫入一筆漫畫資料\n",
    "\n",
    "# 主程式執行流程\n",
    "comic = get_comic_info()  # 取得一筆隨機漫畫資訊\n",
    "save_to_csv(comic)        # 將該筆資料寫入 CSV 檔案"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
